{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab: Linear Regression + Model Evaluation\n",
    "Drew Malter, Matt Winkler    \n",
    "Slalom    \n",
    "July 2018    \n",
    "\n",
    "## Overview\n",
    "The goal of this lab is to provide a hands-on introduction to the main tools/methods for creating and evaluating supervised learning regression models. This lab covers well established regression practices along with statistical reasoning as it works through a problem from start to finish.\n",
    "\n",
    "The examples here utilize data from a large car insurance provider seeking to predict the amount a customer is willing to spend on an insurance policy with given information about each customer.  The benefits of these predictions are extremely valuable to both the sales agents and the marketing team. \n",
    "\n",
    "Sales Agents: Provides them the crucial advatnage of knowing what a customer is probably willing to spend as they help their customers find a plan\n",
    "\n",
    "Marketing: Allows them to focus their marketing campaigns on an audience that will spend more money, or attempt to move a low spending customer base into a higher spending customer base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from ipywidgets import interact, widgets\n",
    "\n",
    "from bokeh.io import push_notebook, show, output_notebook, curdoc\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models.annotations import Title\n",
    "from bokeh.models.widgets import MultiSelect\n",
    "from bokeh.models import Button\n",
    "from bokeh.layouts import widgetbox, column, row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in the data set\n",
    "#Import 3 data sets; orders, prices, and customers\n",
    "os.chdir('C:/Users/drew.malter/Documents/AIML Workshop/SalesDatasets')\n",
    "df = pd.read_csv('CarInsurance_Claims.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add descriptions to each data field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at the first 5 rows of the data set\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return dimension of table\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List data types\n",
    "#note: write line of code to convert those that are necessary\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if there is any missing data.  There are many practices for dealing with missing data if true\n",
    "#Decide what to do about the missing data\n",
    "#I like to input the median value given one or two contraints\n",
    "#but since this is a large data set we can afford to just remove those rows\n",
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop Na's\n",
    "df = df.dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop non numeric fields that we will not need\n",
    "df = df.drop(columns = [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\", \"customer_ID\", \"shopping_pt\", \"record_type\", \"day\", \"location\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at the summary statistics of each numeric field\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some features appear to show skew based on the output above, since the means are higher than the medians.  We will visually confirm this in a few ways and address how to deal with skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot a histogram of car age, note that there are large outliers inflating the mean higher than the median\n",
    "plt.hist(df['car_age'], density=True, bins=30)\n",
    "plt.ylabel('Probability')\n",
    "plt.xlabel('Car Age');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bokeh library provides an interactive interface for examining each feature in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot setup:\n",
    "p = figure(title=\"Test\", \n",
    "           background_fill_color=\"#E8DDCB\", \n",
    "           width=500, \n",
    "           height=300)\n",
    "\n",
    "# get values and make histogram:\n",
    "arr = df['car_age'].values\n",
    "hist, edges = np.histogram(arr, \n",
    "                           density=True, \n",
    "                           bins=50)\n",
    "\n",
    "# Setup x axis based on the data:\n",
    "#arr_min = min(arr)\n",
    "#arr_max = max(arr)\n",
    "#n_unique = len(np.unique(arr))\n",
    "#x = np.linspace(arr_min, arr_max, n_unique)\n",
    "\n",
    "# assign histogram to the figure:\n",
    "r = p.quad(top=hist, bottom=0, left=edges[:-1], right=edges[1:],\n",
    "        fill_color=\"#036564\", line_color=\"#033649\")\n",
    "\n",
    "# labelling:\n",
    "#p.legend.location = \"center_right\"\n",
    "#p.legend.background_fill_color = \"darkgrey\"\n",
    "#p.xaxis.axis_label = 'x'\n",
    "#p.yaxis.axis_label = 'Pr(x)'\n",
    "\n",
    "# show static plot:\n",
    "#show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update() function to make the plot interactive:\n",
    "def update(feature, num_bins):\n",
    "    # update array and histogram values:\n",
    "    arr = df[feature].values\n",
    "    hist, edges = np.histogram(arr, \n",
    "                           density=True, \n",
    "                           bins=num_bins)\n",
    "    \n",
    "    # update plot parameters:\n",
    "    p.title.text = 'Probability distribution of {}'.format(feature)\n",
    "    p.xaxis.axis_label = '{}'.format(feature)\n",
    "    p.yaxis.axis_label = 'Pr({})'.format(feature)\n",
    "    \n",
    "    # reset the renderer data:\n",
    "    r.data_source.data['top'] = hist\n",
    "    r.data_source.data['left'] = edges[:-1]\n",
    "    r.data_source.data['right'] = edges[1:]\n",
    "    \n",
    "    push_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#once converted to numeric variables there will be less options\n",
    "features = df.columns.values\n",
    "nbins = (10, 50)\n",
    "interact(update, feature = features, num_bins = nbins)\n",
    "show(p, notebook_handle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example boxplot for the group size feature. TODO: make dynamic with bokeh\n",
    "sns.boxplot(df['car_age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one possible outlier removal method, lets talk more about this\n",
    "# define outlier adjustment function:\n",
    "def adjust_outliers(array_in):\n",
    "    \"\"\" Finds and replaces outliers in input array with 1.5 * IQR\"\"\"\n",
    "    array_out = np.array(array_in)\n",
    "    \n",
    "    q1 = array_in.quantile(q=0.25)\n",
    "    q3 = array_in.quantile(q=0.75)\n",
    "    iqr = q3 - q1\n",
    "    upper = q3 + 1.5*iqr\n",
    "    lower = q1 - 1.5*iqr\n",
    "    \n",
    "    below_ind = array_out < lower\n",
    "    above_ind = array_out > upper\n",
    "    \n",
    "    array_out[below_ind] = lower\n",
    "    array_out[above_ind] = upper\n",
    "    \n",
    "    changed = np.sum(array_in != array_out)\n",
    "    print('Found and adjusted {} values in {} column'.format(str(changed), array_in.name))\n",
    "    return array_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to fix this\n",
    "# Adjust for outliers across the dataset, except for cost column since it's the output:\n",
    "names = list(df.columns.values)\n",
    "names.remove('cost')\n",
    "df_adj = df[names].apply(adjust_outliers)\n",
    "df_adj['cost'] = df['cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#once above line is fixed\n",
    "# confirm this worked:\n",
    "sns.boxplot(df_adj['car_age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at correlation matrix of numeric variables:\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr = df.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model:\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "lm = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set target to Y, set predictors to X\n",
    "y = df_adj.cost\n",
    "X = df_adj.drop('cost', axis=1)\n",
    "\n",
    "#Split data set into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=101)\n",
    "\n",
    "#Fit the model :\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "#Set predictions\n",
    "lm_train_pred = lm.predict(X_train)\n",
    "lm_test_pred = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a quick PCA for plotting and compare predictions to dummy regressor:\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "regdummy = DummyRegressor(strategy=\"mean\")\n",
    "regdummy.fit(X_train, y_train)\n",
    "dummy_y = regdummy.predict(X_train)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_s = scaler.fit_transform(X_train)\n",
    "\n",
    "pca = PCA(n_components=1)\n",
    "pca.fit(X_s)\n",
    "X_pca = pca.fit_transform(X_s)\n",
    "\n",
    "m, b = np.polyfit(X_pca[:,0], lm_train_pred, 1)\n",
    "plt.plot(X_pca, m*X_pca + b, \"-\", color=\"palevioletred\")\n",
    "plt.axhline(y=regdummy.constant_, linestyle=\"-\", color=\"limegreen\")\n",
    "plt.scatter(X_pca[:,0], lm_train_pred)\n",
    "plt.ylabel(\"Predicted Value\")\n",
    "plt.xlabel(\"Observed X variables index\")\n",
    "plt.title(\"Comparison of Regression with Mean model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return the summary of the model\n",
    "X2 = sm.add_constant(X)\n",
    "est = sm.OLS(y, X2)\n",
    "est2 = est.fit()\n",
    "print(est2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mn = np.mean(y_train)\n",
    "sst = sum((y_train - y_mn)**2)\n",
    "ssr = sum((lm_train_pred - y_train)**2)\n",
    "r2 = 1 - (ssr / sst)\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_adj.target\n",
    "X_names = [nm for nm in df_adj.columns.values if nm != 'cost']\n",
    "X = df_adj.drop(\"cost\", axis=1)\n",
    "\n",
    "def make_predictions(X, y, X_names):\n",
    "    \"\"\"Subset X to selected features, then use to predict y\"\"\"\n",
    "    X = X[X_names]\n",
    "    #Split data set into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=101)\n",
    "    \n",
    "    #Fit the model:\n",
    "    lm.fit(X_train, y_train)\n",
    "    \n",
    "    return X_train, y_train, lm.predict(X_train)\n",
    "    \n",
    "X_train, y_train, lm_train_pred = make_predictions(X, y, X_names)\n",
    "\n",
    "def make_plot_arrays(X_train, lm_train_pred):\n",
    "    \"\"\"Get first PCA component from X_train for plotting only\"\"\"\n",
    "    # fitting PCA:\n",
    "    X_s = scaler.fit_transform(X_train)\n",
    "    pca = PCA(n_components=1)\n",
    "    pca.fit(X_s)\n",
    "    X_pca = pca.fit_transform(X_s)\n",
    "    # make plot lines:\n",
    "    m, b = np.polyfit(X_pca[:,0], lm_train_pred, 1)\n",
    "    x_arr = X_pca[:, 0]\n",
    "    \n",
    "    # normalize so the scale doesn't change with different sets of features\n",
    "    x_arr_norm = ( (x_arr - x_arr.min()) / (x_arr.max() - x_arr.min()) )\n",
    "    \n",
    "    y_arr = m*X_pca[:, 0] + b\n",
    "    \n",
    "    return x_arr_norm, y_arr\n",
    "\n",
    "x_arr, y_arr = make_plot_arrays(X_train, lm_train_pred)\n",
    "\n",
    "def calc_r2(y_train, preds):\n",
    "    y_mn = np.mean(y_train)\n",
    "    sst = sum((y_train - y_mn)**2)\n",
    "    ssr = sum((y_train - preds)**2)\n",
    "    \n",
    "    r2 = 1 - (ssr / sst)\n",
    "    return np.round(r2, 4)\n",
    "\n",
    "baseline_r2 = calc_r2(y_train, dummy_y)\n",
    "pred_r2 = calc_r2(y_train, lm_train_pred)\n",
    "\n",
    "p = figure(title=\"Regression model vs. baseline\", \n",
    "           plot_height=300, \n",
    "           plot_width=600, \n",
    "           y_range=(0,60))\n",
    "\n",
    "# scatterplot of actual data:\n",
    "r1 = p.circle(x_arr, y_train, size=10, color=\"green\", alpha=0.5)\n",
    "# scatterplot of prediction data:\n",
    "r2 = p.circle(x_arr, lm_train_pred, size=10, color=\"pink\", alpha=0.5)\n",
    "# regression model:\n",
    "r3 = p.line(x_arr, y_arr, color=\"#2222aa\", line_width=3)\n",
    "# baseline dummy model:\n",
    "p.line(x_arr, dummy_y, color=\"purple\", line_width=2)\n",
    "\n",
    "p.xaxis.axis_label = 'X feature array index'\n",
    "p.yaxis.axis_label = 'Predicted price'\n",
    "\n",
    "#show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_opts = [nm for nm in df_adj.columns.values if nm != 'cost']\n",
    "\n",
    "m = widgets.SelectMultiple(\n",
    "    options=X_opts,\n",
    "    value=X_opts,\n",
    "    rows=10,\n",
    "    description='Features',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "def update_regression(features):\n",
    "    X_selected = list(features)\n",
    "    \n",
    "    # update predictions based on selected features:\n",
    "    X_train, y_train, lm_train_pred = make_predictions(X, y, X_selected)\n",
    "    x_arr, y_arr = make_plot_arrays(X_train, lm_train_pred)\n",
    "    \n",
    "    # update plots:\n",
    "    r1.data_source.data['x'] = x_arr\n",
    "    r1.data_source.data['y'] = y_train\n",
    "    \n",
    "    r2.data_source.data['x'] = x_arr\n",
    "    r2.data_source.data['y'] = lm_train_pred\n",
    "    \n",
    "    r3.data_source.data['x'] = x_arr\n",
    "    r3.data_source.data['y'] = y_arr\n",
    "    \n",
    "    pred_r2 = calc_r2(y_train, lm_train_pred)\n",
    "    baseline_r2 = calc_r2(y_train, dummy_y)\n",
    "    \n",
    "    print('Predicted R^2: {}'.format(pred_r2))\n",
    "    print('Baseline R^2: {}'.format(baseline_r2))\n",
    "    push_notebook()\n",
    "    \n",
    "interact(update_regression, features = m)\n",
    "show(p, notebook_handle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
